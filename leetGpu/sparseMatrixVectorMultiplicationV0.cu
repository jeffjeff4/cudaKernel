//method0
/*
#include <cuda_runtime.h>

#define FULL_MASK 0xffffffff
#define BLOCK 32

__global__ void matrixVecMultiply(const float* A, const float* x, float* y, int M, int N, int nnz) {
    int row = blockIdx.x;
    int tid = threadIdx.x;
    float sum = 0.0f;
    for (int i=tid; i<N; i+=BLOCK) {
        sum += A[row*N +i] * x[i];
    }
    for (int i = BLOCK/2; i>0; i>>=1) {
        sum += __shfl_down_sync(FULL_MASK, sum, i);
    }
    if (tid == 0) {
        y[row] = sum;
    }
}

// A, x, y are device pointers
extern "C" void solve(const float* A, const float* x, float* y, int M, int N, int nnz) {
    matrixVecMultiply<<<M, BLOCK>>>(A, x, y, M, N, nnz);
} 
*/

//---------------------------------------------------------------------------------------------------
//method1
///*
#include <cuda_runtime.h>

template<int WARP_SIZE = 32>
__forceinline__ __device__ float warpReduceSum(float val) {
    for (int mask = WARP_SIZE >> 1; mask >= 1; mask >>= 1) {
        val += __shfl_xor_sync(0xffffffff, val, mask);
    }
    return val;
}
        
__global__ void matrixVecMultiply(const float* __restrict__ A, const float* __restrict__ x, float* __restrict__ y, int M, int N, int nnz) {
    int tx = threadIdx.x;
    int ty = threadIdx.y;
    int tid = threadIdx.x + blockDim.x * ty;

    int bx = blockIdx.x;
    const int WARP_SIZE = 32;
    int lane = tid % WARP_SIZE;
    int m = blockDim.y * bx + ty;
    const int pack_size = 4;
    int pack_num = N / pack_size;
    int pack_off = pack_size * pack_num;

    float4* a_f4_ptr = (float4*)(A + m * N);
    float4* x_f4_ptr = (float4*)x;

    if (m < M) {
        float val = 0.0f;

        #pragma unroll
        for (int i = tx; i < pack_num; i += blockDim.x) {
            float4 a_float4 = *(a_f4_ptr + i);
            float4 x_float4 = *(x_f4_ptr + i);

            val += a_float4.x * x_float4.x + 
                   a_float4.y * x_float4.y + 
                   a_float4.z * x_float4.z + 
                   a_float4.w * x_float4.w;
        }

        #pragma unroll
        for (int i = pack_off + tx; i < N; i += blockDim.x) {
            val += A[m * N + i] * x[i];
        }
        val = warpReduceSum<WARP_SIZE>(val);
        if (lane == 0) {
            y[m] = val;
        }
    }
}

// A, x, y are device pointers
extern "C" void solve(const float* A, const float* x, float* y, int M, int N, int nnz) {
    dim3 grid((M+3) / 4);
    dim3 block(32, 4);
    matrixVecMultiply<<<grid, block>>>(A, x, y, M, N, nnz);
} 
//*/


//--------------------------------------------------------------------------------------------------
/*
question0:
不理解，请解释，用例子


好的，我来绘制一个详细的示意图，说明这种二维 tiling 是如何映射到 M×N 矩阵的。

## **示意图：二维 Tiling 映射到 M×N 矩阵**

```
================================================================================
                    矩阵 A: M 行 × N 列
================================================================================

          列方向 (N 列)
       0   1   2   3  ...  N-3 N-2 N-1
行   ┌───┬───┬───┬───┬───┬───┬───┬───┐
方 0 │   │   │   │   │   │   │   │   │ ← Block 0, Warp 0 (ty=0): 计算 y[0]
向   ├───┼───┼───┼───┼───┼───┼───┼───┤
(M 1 │   │   │   │   │   │   │   │   │ ← Block 0, Warp 1 (ty=1): 计算 y[1]
行)  ├───┼───┼───┼───┼───┼───┼───┼───┤
   2 │   │   │   │   │   │   │   │   │ ← Block 0, Warp 2 (ty=2): 计算 y[2]
     ├───┼───┼───┼───┼───┼───┼───┼───┤
   3 │   │   │   │   │   │   │   │   │ ← Block 0, Warp 3 (ty=3): 计算 y[3]
     ├───┼───┼───┼───┼───┼───┼───┼───┤
   4 │   │   │   │   │   │   │   │   │ ← Block 1, Warp 0 (ty=0): 计算 y[4]
     ├───┼───┼───┼───┼───┼───┼───┼───┤
   5 │   │   │   │   │   │   │   │   │ ← Block 1, Warp 1 (ty=1): 计算 y[5]
     ├───┼───┼───┼───┼───┼───┼───┼───┤
   6 │   │   │   │   │   │   │   │   │ ← Block 1, Warp 2 (ty=2): 计算 y[6]
     ├───┼───┼───┼───┼───┼───┼───┼───┤
   7 │   │   │   │   │   │   │   │   │ ← Block 1, Warp 3 (ty=3): 计算 y[7]
     ├───┼───┼───┼───┼───┼───┼───┼───┤
     :   :   :   :   :   :   :   :   : 
     ├───┼───┼───┼───┼───┼───┼───┼───┤
 M-1 │   │   │   │   │   │   │   │   │ ← Block K, Warp (ty): 计算 y[M-1]
     └───┴───┴───┴───┴───┴───┴───┴───┘
     
其中：K = (M + 3) / 4 - 1
```

## **详细分解图**

### **1. Grid 和 Block 维度映射**

```
dim3 grid((M+3)/4);   // x 方向：每个 block 负责 4 行，计算需要的 block 数
dim3 block(32, 4);    // block 内部：x=32线程，y=4线程（形成4个warp）
```

### **2. Block 到行的映射（垂直方向）**

```
┌─────────────────────────────────────────────────────┐
│                矩阵行映射关系                        │
├─────────────────────────────────────────────────────┤
│ 公式: m = blockDim.y * blockIdx.x + threadIdx.y     │
│      = 4 * blockIdx.x + threadIdx.y                 │
├─────────────────────────────────────────────────────┤
│                                                     │
│ Block 0: 负责行 0,1,2,3                             │
│   blockIdx.x=0 → m = 4*0 + ty = ty                  │
│     ty=0 → m=0, ty=1 → m=1, ty=2 → m=2, ty=3 → m=3  │
│                                                     │
│ Block 1: 负责行 4,5,6,7                             │
│   blockIdx.x=1 → m = 4*1 + ty = 4 + ty              │
│     ty=0 → m=4, ty=1 → m=5, ty=2 → m=6, ty=3 → m=7  │
│                                                     │
│ Block 2: 负责行 8,9,10,11                           │
│   blockIdx.x=2 → m = 4*2 + ty = 8 + ty              │
│                                                     │
│ ...                                                 │
│                                                     │
│ Block K: 负责最后4行                                │
│   K = ceil(M/4) - 1                                │
│   如果 M 不是4的倍数，最后一个 block 可能部分有效    │
└─────────────────────────────────────────────────────┘
```

### **3. 线程到列的映射（水平方向）**

```
N 列矩阵的列方向映射（以 Warp 0 计算 y[0] 为例）：

       列 0~N-1
     ┌─────────────────────────────────────────────┐
     │ 每个线程负责 N/32 列（间隔32列采样）         │
     │                                             │
     │ Thread 0 (tx=0): 负责列 0, 32, 64, 96, ...  │
     │ Thread 1 (tx=1): 负责列 1, 33, 65, 97, ...  │
     │ Thread 2 (tx=2): 负责列 2, 34, 66, 98, ...  │
     │ ...                                         │
     │ Thread 31(tx=31):负责列 31, 63, 95, 127,... │
     │                                             │
     │ 内存访问模式（使用 float4 向量化）：         │
     │                                             │
     │ 线程 tx 访问的 float4 索引：                 │
     │   i = tx, tx+32, tx+64, ... < pack_num      │
     │                                             │
     │ 其中 pack_num = N / 4                       │
     │ 每个 float4 包含4个连续的 float 元素         │
     └─────────────────────────────────────────────┘
```

### **4. 完整的映射可视化（以 M=12, N=64 为例）**

```
M = 12 行, N = 64 列
grid = ( (12+3)/4 ) = (15/4) = 3.75 → 4 个blocks
block = (32, 4) → 每个block 128线程，4个warp

┌─────────────────────────────────────────────────────────────────┐
│                        矩阵 A[12×64]                            │
├─────┬───────────────────────────────────────────────────────────┤
│ Block │ 负责的行      Warp分配           线程在行内的列分配      │
├─────┼───────────────────────────────────────────────────────────┤
│       │               ┌─────────────────────────────────────┐   │
│ Block 0 │ 行 0-3     │ Warp 0 (ty=0): 计算 y[0]            │   │
│ (bx=0) │             │   - 32个线程协作                     │   │
│       │             │   - 每个线程负责2列（64列/32线程）    │   │
│       │             │   - Thread 0: 列 0,32                │   │
│       │             │   - Thread 1: 列 1,33                │   │
│       │             │   - ... Thread 31: 列 31,63          │   │
│       │             └─────────────────────────────────────┘   │
│       │             ┌─────────────────────────────────────┐   │
│       │             │ Warp 1 (ty=1): 计算 y[1]            │   │
│       │             │   类似分配                          │   │
│       │             └─────────────────────────────────────┘   │
│       │             ┌─────────────────────────────────────┐   │
│       │             │ Warp 2 (ty=2): 计算 y[2]            │   │
│       │             └─────────────────────────────────────┘   │
│       │             ┌─────────────────────────────────────┐   │
│       │             │ Warp 3 (ty=3): 计算 y[3]            │   │
│       │             └─────────────────────────────────────┘   │
├─────┼───────────────────────────────────────────────────────────┤
│ Block 1 │ 行 4-7     │ Warp 0: 计算 y[4]                      │   │
│ (bx=1) │             │ Warp 1: 计算 y[5]                      │   │
│       │             │ Warp 2: 计算 y[6]                      │   │
│       │             │ Warp 3: 计算 y[7]                      │   │
├─────┼───────────────────────────────────────────────────────────┤
│ Block 2 │ 行 8-11    │ Warp 0: 计算 y[8]                      │   │
│ (bx=2) │             │ Warp 1: 计算 y[9]                      │   │
│       │             │ Warp 2: 计算 y[10]                     │   │
│       │             │ Warp 3: 计算 y[11]                     │   │
├─────┼───────────────────────────────────────────────────────────┤
│ Block 3 │ 行 12-15   │ 只有部分有效（M=12，最后4行无效）       │   │
│ (bx=3) │             │ 通过 if (m < M) 检查跳过               │   │
└─────┴───────────────────────────────────────────────────────────┘
```

### **5. 内存访问模式示意图**

```
列方向的内存访问（以 Warp 0 计算 y[0] 为例）：

时间步 t0:                    时间步 t1:
所有32个线程同时读取          所有32个线程同时读取
┌─────────────────────┐      ┌─────────────────────┐
│ Thread 0: A[0][0-3]  │      │ Thread 0: A[0][32-35]│
│ Thread 1: A[0][4-7]  │      │ Thread 1: A[0][36-39]│
│ Thread 2: A[0][8-11] │      │ Thread 2: A[0][40-43]│
│ ...                 │      │ ...                 │
│ Thread31:A[0][124-127]│    │ Thread31:A[0][156-159]│
└─────────────────────┘      └─────────────────────┘
     ↓                           ↓
  合并访问                     合并访问
(连续32×16B=512B)           (连续32×16B=512B)
     ↓                           ↓
  高速缓存                     高速缓存
```

### **6. 计算流程图**

```
开始
  ↓
每个 Block 启动 (32×4=128线程)
  ↓
├───────────────── Block 0 ─────────────────┐
│ 计算 m = 4*bx + ty                         │
│ if (m < M) { // 边界检查                   │
│   每个线程计算部分和 val = 0              │
│                                           │
│   // 列方向循环                           │
│   for (i = tx; i < pack_num; i += 32) {   │
│      读取 A[m][i*4  : i*4+3]  ← float4   │
│      读取 x[i*4    : i*4+3]   ← float4   │
│      val += dot(a_float4, x_float4)      │
│   }                                       │
│                                           │
│   // 处理剩余列（如果不是4的倍数）         │
│   for (i = pack_off+tx; i < N; i += 32) { │
│      val += A[m][i] * x[i]               │
│   }                                       │
│                                           │
│   // Warp 内归约                          │
│   val = warpReduceSum(val)               │
│                                           │
│   // 只有 lane 0 写结果                   │
│   if (lane == 0) y[m] = val;             │
│ }                                         │
└───────────────────────────────────────────┘
  ↓
重复 for 所有 blocks
  ↓
结束
```

### **7. 边界情况处理**

当 M 不是4的倍数时（比如 M=10）：

```
grid = (10+3)/4 = 13/4 = 3.25 → 4 blocks

有效计算：
Block 0: 计算行 0,1,2,3  ✓
Block 1: 计算行 4,5,6,7  ✓
Block 2: 计算行 8,9      ✓ (行10,11被 if (m < M) 跳过)
Block 3: 全部跳过        ✗ (行12-15 >= M)

if (m < M) 确保只计算有效行：
  m = 4*bx + ty
  bx=0: m=0,1,2,3  < 10 ✓
  bx=1: m=4,5,6,7  < 10 ✓
  bx=2: m=8,9,10,11 → 只有8,9有效
  bx=3: m=12,13,14,15 → 全部无效
```

### **8. 性能优势总结**

这种映射设计的优势：

1. **合并内存访问**：每个 warp 的32个线程同时读取连续内存
2. **向量化加载**：使用 float4 一次读取4个元素
3. **无 bank 冲突**：线程访问模式规则
4. **高效归约**：warp shuffle 比共享内存快
5. **负载均衡**：所有线程工作量相似

### **9. 实际执行时间线**

```
时间轴:    t0     t1     t2     t3     t4
        ↓      ↓      ↓      ↓      ↓
SM 0: [Block0] [Block1] [Block2] [Block3] ...
        ├───────┤
        Warp0: 计算 y[0] → 归约 → 写 y[0]
        Warp1: 计算 y[1] → 归约 → 写 y[1]
        Warp2: 计算 y[2] → 归约 → 写 y[2]
        Warp3: 计算 y[3] → 归约 → 写 y[3]
```

这种二维 tiling 映射是一种非常经典的 CUDA 优化模式，特别适合矩阵-向量乘法这类操作。它平衡了并行度、内存访问效率和计算密度！

//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question1:
不理解，请解释，用例子

dim3 block(32, 4);
const int pack_size = 4;

blockDim.y=4, pack_size = 4
这两个4的值是一样的，是巧合，还是by design?

**这不是巧合，这是精心设计的（by design）！** 这两个4有紧密的数学关系。

让我详细解释为什么这两个4是相关的：

## 1. **设计原理分析**

### 代码中的关键参数：
```cpp
dim3 block(32, 4);      // block 维度：x=32, y=4
const int pack_size = 4; // 向量化加载：一次读取4个float
```

### 它们的关系：
```
blockDim.y = 4  ↔  pack_size = 4
└── 每个 block 负责4行    └── 每次读取4个元素
```

## 2. **为什么这么设计？内存访问模式**

### 理想的内存访问模式：
```
对于矩阵 A 的第 m 行：
我们希望 Warp 的32个线程能一次性读取：
   32 threads × pack_size = 128个 float 元素
   128 floats × 4 bytes = 512字节（GPU缓存线大小）
```

### 实际内存访问：
```cpp
float4* a_f4_ptr = (float4*)(A + m * N);

// 线程 tx 访问：
float4 a_float4 = *(a_f4_ptr + i);
// 这读取了：A[m][i*4], A[m][i*4+1], A[m][i*4+2], A[m][i*4+3]
```

## 3. **数学关系推导**

### 情况1：如果 blockDim.y 和 pack_size 不同
假设 `blockDim.y = 8`, `pack_size = 4`：

```
block(32, 8) → 256个线程，8个warp
每个 block 负责8行
pack_size=4 → 每次读取4个元素

问题：没有直接的数学关系，内存访问可能不优化
```

### 情况2：当前设计 `blockDim.y = pack_size = 4`
```
block(32, 4) → 128个线程，4个warp
每个 block 负责4行
pack_size=4 → 每次读取4个元素

优点：有优美的数学关系！
```

## 4. **隐藏的数学美**

### 观察这个循环：
```cpp
#pragma unroll
for (int i = tx; i < pack_num; i += blockDim.x) {
    // i = tx, tx+32, tx+64, ...
    float4 a_float4 = *(a_f4_ptr + i);
    // 读取 A[m][i*4 : i*4+3]
}
```

这里：
- `blockDim.x = 32`（线程在x方向）
- `pack_size = 4`（向量化大小）
- `blockDim.y = 4`（线程在y方向）

**关键洞察**：`blockDim.y` 和 `pack_size` 相同使得**每个线程负责的元素数量规整**。

## 5. **具体计算示例**

假设 `N = 128`：

### 每个线程的工作量：
```
pack_num = N / pack_size = 128 / 4 = 32
每个线程的迭代次数 = ceil(pack_num / blockDim.x) = ceil(32/32) = 1
```

### 内存访问模式：
```
时间步 t0:
Warp 0 (计算 y[0]) 的32个线程：
    Thread 0: 读取 A[0][0-3]
    Thread 1: 读取 A[0][4-7]
    ...
    Thread 31: 读取 A[0][124-127]
    
一次性读取了整行（128个元素）！
```

## 6. **如果改变其中一个值会怎样？**

### 实验1：`blockDim.y = 8`, `pack_size = 4`
```cpp
dim3 block(32, 8);      // 256线程
const int pack_size = 4;

// 问题：
// 1. 每个 block 负责8行，但 pack_size=4
// 2. 没有直接的数学关系
// 3. 可能不是最优的缓存使用
```

### 实验2：`blockDim.y = 4`, `pack_size = 2`
```cpp
dim3 block(32, 4);      // 128线程
const int pack_size = 2; // float2

// 问题：
// 1. pack_size=2 → 每次只读取2个元素
// 2. 向量化程度降低
// 3. 可能无法充分利用内存带宽
```

### 实验3：`blockDim.y = 8`, `pack_size = 8`
```cpp
dim3 block(32, 8);      // 256线程
const int pack_size = 8; // 需要自定义 float8 类型

// 理论上更好，但：
// 1. CUDA 只原生支持到 float4
// 2. 需要自定义数据结构
// 3. 对齐要求更严格
```

## 7. **最优选择的数学证明**

### 目标：最大化内存带宽利用率
```
GPU 内存系统特点：
- 喜欢对齐的访问（32字节、64字节、128字节边界）
- 喜欢连续的访问模式
- 喜欢大块传输

最佳实践：
1. 使用最大向量化（float4 = 16字节）
2. 让 warp 一次性读取缓存线大小（通常128字节）
3. 保持规整的访问模式
```

### 当前设计的优越性：
```
对于每个 warp（32线程）：
   每个线程读取 float4 = 16字节
   32线程 × 16字节 = 512字节
   
512字节正好是：
   - 许多 GPU 的 L1 缓存线大小
   - 或 L2 缓存线的大小倍数
   - 完美对齐的访问
```

## 8. **与硬件特性的匹配**

### NVIDIA GPU 的内存层次：
```
寄存器 (最快)
   ↓
L1 缓存 / 共享内存
   ↓
L2 缓存
   ↓
全局内存 (最慢)
```

### 当前设计如何匹配：
```
blockDim.y = 4, pack_size = 4 的设计：

1. 合并访问：32个线程读取连续的512字节
2. 缓存友好：512字节 ≈ 缓存线大小
3. 计算密度：每个线程4次乘加操作
4. 规整性：所有参数都是2的幂次
```

## 9. **其他可能的优化组合**

虽然 `blockDim.y = pack_size = 4` 是好的选择，但还有其他可能：

### 选项A：`blockDim.y = 2`, `pack_size = 4`
```cpp
dim3 block(32, 2);      // 64线程，2个warp/block
// 优点：更细粒度，适合小矩阵
// 缺点：可能 underutilize GPU
```

### 选项B：`blockDim.y = 4`, `pack_size = 1`（无向量化）
```cpp
dim3 block(32, 4);      // 128线程
const int pack_size = 1; // 无向量化
// 优点：简单
// 缺点：内存带宽利用率减半
```

### 选项C：`blockDim.y = 8`, `pack_size = 4`（前面分析过）
```cpp
dim3 block(32, 8);      // 256线程
const int pack_size = 4;
// 可能在某些情况下更好，但需要测试
```

## 10. **实际性能考量**

### 通过 roofline 模型分析：
```
计算强度 = 操作数 / 字节数

当前设计：
- 每个 float4 读取：16字节
- 每个 float4 计算：4次乘加 = 8次浮点操作
- 计算强度 = 8 ops / 16 bytes = 0.5 ops/byte

如果 pack_size=2：
- 计算强度 = 4 ops / 8 bytes = 0.5 ops/byte（相同）
- 但内存事务数加倍！

所以 pack_size=4 更好：相同计算强度，更少内存事务。
```

## 11. **设计者的思考过程**

我推测原始设计者的思路：

```
1. 目标：高效矩阵-向量乘法
2. 约束：使用 warp shuffle 进行归约
3. 选择：一个 warp 计算一行
4. 优化：使用 float4 向量化
5. 调整：让 blockDim.y = pack_size 保持规整
6. 验证：通过性能测试确认
```

## 12. **总结**

**`blockDim.y = 4` 和 `pack_size = 4` 相同是 by design，不是巧合！**

### 原因：
1. **数学规整性**：保持参数为2的幂次，便于计算
2. **内存访问优化**：warp 的32个线程能一次性读取整行（当 N 是128的倍数时）
3. **硬件匹配**：512字节访问对齐缓存线
4. **代码简洁**：循环边界计算简单
5. **性能最佳**：平衡了并行度、内存带宽和计算密度

### 经验法则：
在 CUDA 优化中，经常看到这种模式：
- **向量化大小** 与 **block 的某个维度** 相同
- 所有参数都是 **2的幂次**
- 设计目标是 **最大化内存带宽利用率**

这是一个经典的 CUDA 优化技巧，体现了"让硬件高兴"的编程哲学！
//--------------------------------------------------------------------------------------------------



//--------------------------------------------------------------------------------------------------
/*
question2:
不理解，请解释，用例子


//--------------------------------------------------------------------------------------------------



//--------------------------------------------------------------------------------------------------
/*
question3:
不理解，请解释，用例子


//--------------------------------------------------------------------------------------------------
