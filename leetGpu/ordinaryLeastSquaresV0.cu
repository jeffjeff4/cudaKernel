#include <cuda_runtime.h>
#include <vector>
#include <cmath>
#include <cstdio>

// Compute XtX = X^T * X
__global__ void compute_xtx(const float* __restrict__ X,
                            float* __restrict__ XtX,
                            int n_samples, int n_features) {
    int i = blockIdx.y * blockDim.y + threadIdx.y; // feature i
    int j = blockIdx.x * blockDim.x + threadIdx.x; // feature j
    if (i >= n_features || j >= n_features) return;

    float sum = 0.0f;
    for (int k = 0; k < n_samples; ++k)
        sum += X[k * n_features + i] * X[k * n_features + j];

    XtX[i * n_features + j] = sum;
}

// Compute Xty = X^T * y
__global__ void compute_xty(const float* __restrict__ X,
                            const float* __restrict__ y,
                            float* __restrict__ Xty,
                            int n_samples, int n_features) {
    int i = blockIdx.x * blockDim.x + threadIdx.x; // feature index
    if (i >= n_features) return;

    float sum = 0.0f;
    for (int k = 0; k < n_samples; ++k)
        sum += X[k * n_features + i] * y[k];
    Xty[i] = sum;
}

// CPU Gaussâ€“Jordan elimination
void cpu_gauss_jordan(std::vector<float>& A, std::vector<float>& b, int n) {
    for (int i = 0; i < n; ++i) {
        float pivot = A[i * n + i];
        if (fabs(pivot) < 1e-8f) pivot = (pivot >= 0 ? 1e-8f : -1e-8f);
        for (int j = 0; j < n; ++j) A[i * n + j] /= pivot;
        b[i] /= pivot;

        for (int k = 0; k < n; ++k) {
            if (k == i) continue;
            float factor = A[k * n + i];
            for (int j = 0; j < n; ++j)
                A[k * n + j] -= factor * A[i * n + j];
            b[k] -= factor * b[i];
        }
    }
}

extern "C" void solve(const float* X, const float* y, float* beta,
                      int n_samples, int n_features) {
    float *d_XtX, *d_Xty;
    cudaMalloc(&d_XtX, sizeof(float) * n_features * n_features);
    cudaMalloc(&d_Xty, sizeof(float) * n_features);

    dim3 block(16, 16);
    dim3 grid((n_features + 15) / 16, (n_features + 15) / 16);
    compute_xtx<<<grid, block>>>(X, d_XtX, n_samples, n_features);

    int threads = 256;
    int blocks = (n_features + threads - 1) / threads;
    compute_xty<<<blocks, threads>>>(X, y, d_Xty, n_samples, n_features);

    // Copy back to host
    std::vector<float> h_XtX(n_features * n_features);
    std::vector<float> h_Xty(n_features);
    cudaMemcpy(h_XtX.data(), d_XtX, sizeof(float) * n_features * n_features, cudaMemcpyDeviceToHost);
    cudaMemcpy(h_Xty.data(), d_Xty, sizeof(float) * n_features, cudaMemcpyDeviceToHost);

    cpu_gauss_jordan(h_XtX, h_Xty, n_features);

    cudaMemcpy(beta, h_Xty.data(), sizeof(float) * n_features, cudaMemcpyHostToDevice);

    cudaFree(d_XtX);
    cudaFree(d_Xty);
}




//--------------------------------------------------------------------------------------------------
/*
question0:

ä¸ç†è§£ï¼Œè¯·è§£é‡Šï¼Œç”¨ä¾‹å­

è¿™æ®µä»£ç å®ç°äº†ä¸€ä¸ªåŸºäº**æœ€å°äºŒä¹˜æ³• (Least Squares)** çš„çº¿æ€§å›å½’æ±‚è§£å™¨ã€‚å®ƒåˆ©ç”¨ GPU (CUDA) æ¥é«˜æ•ˆåœ°è®¡ç®—**æ­£è§„æ–¹ç¨‹ (Normal Equation)** ä¸­çš„çŸ©é˜µä¹˜æ³•éƒ¨åˆ†ï¼Œç„¶åå°†ç»“æœä¼ å› CPU ä½¿ç”¨ **é«˜æ–¯-çº¦æ—¦æ¶ˆå…ƒæ³• (Gaussâ€“Jordan elimination)** æ±‚è§£ç³»æ•°ã€‚

-----

## âš™ï¸ I. æ ¸å¿ƒæ•°å­¦åŸç†ï¼šæ­£è§„æ–¹ç¨‹

çº¿æ€§å›å½’çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ç³»æ•°å‘é‡ \beta æ¥æœ€å°åŒ–è¯¯å·®ã€‚é€šè¿‡æ±‚è§£æ­£è§„æ–¹ç¨‹å¯ä»¥å¾—åˆ° \betaï¼š

X^T X \beta = X^T y

è¿™æ®µ CUDA ä»£ç é€šè¿‡ä¸¤ä¸ª Kernel å’Œä¸€ä¸ª CPU å‡½æ•°æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š

1.  **Kernel `compute_xtx`:** è®¡ç®— X^T X çŸ©é˜µã€‚
2.  **Kernel `compute_xty`:** è®¡ç®— X^T y å‘é‡ã€‚
3.  **CPU `cpu_gauss_jordan`:** æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„ (X^T X) \beta = (X^T y)ã€‚

-----

## ğŸš€ II. GPU æ ¸å¿ƒè®¡ç®— (Kernel Breakdown)

### 1\. è®¡ç®— X^T X (`compute_xtx`)

è¯¥ Kernel è®¡ç®—çŸ©é˜µ C = A * B çš„ç‰¹æ®Šå½¢å¼ï¼Œå…¶ä¸­ A = X^T å’Œ B = Xã€‚

  * **è¾“å…¥:** X (N_samples * N_features çŸ©é˜µ)
  * **è¾“å‡º:** X^T X (N_features * N_features çŸ©é˜µ)

<!-- end list -->

```c
__global__ void compute_xtx(...) 
    int i = blockIdx.y * blockDim.y + threadIdx.y; // feature i (row index)
    int j = blockIdx.x * blockDim.x + threadIdx.x; // feature j (col index)
    if (i >= n_features || j >= n_features) return; // è¾¹ç•Œæ£€æŸ¥

    float sum = 0.0f;
    for (int k = 0; k < n_samples; ++k)
        sum += X[k * n_features + i] * X[k * n_features + j]; // ç‚¹ç§¯ç´¯åŠ 
    XtX[i * n_features + j] = sum;

```

  * **åˆ†å·¥:** æ¯ä¸ªçº¿ç¨‹ (i, j) è´Ÿè´£è®¡ç®— X^T X çŸ©é˜µä¸­çš„ä¸€ä¸ªå…ƒç´  (i, j)ã€‚
  * **æ ¸å¿ƒè®¡ç®—:** å†…å±‚å¾ªç¯ (å˜é‡ k, éå†æ ·æœ¬æ•° N_samples) è®¡ç®— X çŸ©é˜µçš„ç¬¬ i åˆ—å’Œç¬¬ j åˆ—çš„**ç‚¹ç§¯**ã€‚

> **ç¤ºä¾‹:** å‡è®¾ i=0, j=1ã€‚çº¿ç¨‹è®¡ç®— X^T X_0, 1ã€‚
> X^T X_0, 1 = \sum_k=0^N_samples-1 X_k, 0 * X_k, 1
> çº¿ç¨‹ t è¿­ä»£ k å˜é‡ï¼Œç´¯åŠ  X çŸ©é˜µç¬¬ 0 åˆ—å’Œç¬¬ 1 åˆ—çš„ä¹˜ç§¯ã€‚

### 2\. è®¡ç®— X^T y (`compute_xty`)

è¯¥ Kernel è®¡ç®—å‘é‡ b = A * v çš„ç‰¹æ®Šå½¢å¼ï¼Œå…¶ä¸­ A = X^T å’Œ v = yã€‚

  * **è¾“å…¥:** X, y (N_samples * 1 å‘é‡)
  * **è¾“å‡º:** Xty (N_features * 1 å‘é‡)

<!-- end list -->

```c
__global__ void compute_xty(...) 
    int i = blockIdx.x * blockDim.x + threadIdx.x; // feature index
    if (i >= n_features) return;

    float sum = 0.0f;
    for (int k = 0; k < n_samples; ++k)
        sum += X[k * n_features + i] * y[k]; // ç‚¹ç§¯ç´¯åŠ 
    Xty[i] = sum;

```

  * **åˆ†å·¥:** æ¯ä¸ªçº¿ç¨‹ i è´Ÿè´£è®¡ç®— X^T y å‘é‡ä¸­çš„ä¸€ä¸ªå…ƒç´  iã€‚
  * **æ ¸å¿ƒè®¡ç®—:** å†…å±‚å¾ªç¯ (k) è®¡ç®— X çŸ©é˜µçš„ç¬¬ i åˆ—å’Œ y å‘é‡çš„**ç‚¹ç§¯**ã€‚

-----

## ğŸ’» III. CPU æ±‚è§£ä¸æ•°æ®æµ (`cpu_gauss_jordan` å’Œ `solve`)

### 1\. CPU é«˜æ–¯-çº¦æ—¦æ¶ˆå…ƒæ³•

```c
void cpu_gauss_jordan(std::vector<float>& A, std::vector<float>& b, int n) 
    // ... (å¾ªç¯æ‰§è¡Œè¡Œå˜æ¢) ...

```

  * **ä½œç”¨:** è¿™æ˜¯ä¸€ä¸ªæ ‡å‡†çš„ **é«˜æ–¯-çº¦æ—¦æ¶ˆå…ƒæ³•** å®ç°ã€‚è¯¥ç®—æ³•æ¥æ”¶ X^T X çŸ©é˜µ (A) å’Œ X^T y å‘é‡ (b)ï¼Œå¹¶å¯¹**å¢å¹¿çŸ©é˜µ** [A | b] æ‰§è¡Œè¡Œå˜æ¢ã€‚
  * **ç»“æœ:** ç®—æ³•ç»“æŸæ—¶ï¼ŒA çŸ©é˜µå˜ä¸º**å•ä½çŸ©é˜µ**ï¼Œè€Œ b å‘é‡åˆ™å˜ä¸ºè§£å‘é‡ \betaã€‚

### 2\. ä¸»å‡½æ•° (`solve`) çš„æ•°æ®æµ

`solve` å‡½æ•°è´Ÿè´£åè°ƒ CPU å’Œ GPU çš„å·¥ä½œï¼š

1.  **GPU å†…å­˜åˆ†é…:** åˆ†é… GPU å†…å­˜ç”¨äºå­˜å‚¨ X^T X (d_XtX) å’Œ X^T y (d_Xty)ã€‚
2.  **GPU å¯åŠ¨:** å¯åŠ¨ä¸¤ä¸ª Kernel å®ŒæˆçŸ©é˜µä¹˜æ³•ã€‚
3.  **æ•°æ®æ‹·è´ (Device \rightarrow Host):** `cudaMemcpy` å°†è®¡ç®—å‡ºçš„ d_XtX å’Œ d_Xty æ‹·è´å› CPU çš„ `std::vector`ã€‚
4.  **CPU æ±‚è§£:** è°ƒç”¨ `cpu_gauss_jordan(h_XtX, h_Xty, n_features)` åœ¨ CPU ä¸Šæ±‚è§£ã€‚æ­¤æ—¶ h_Xty å˜æˆäº†ç³»æ•° \betaã€‚
5.  **æ•°æ®æ‹·è´ (Host \rightarrow Device):** å°†æœ€ç»ˆçš„ç³»æ•° \beta (å­˜å‚¨åœ¨ h_Xty) æ‹·è´å› GPU å†…å­˜æŒ‡é’ˆ betaï¼ˆæœ€ç»ˆçš„è¾“å‡ºï¼‰ã€‚

**æ€»ç»“:** è¿™æ˜¯ä¸€ç§æ··åˆæ¶æ„æ–¹æ³•ï¼Œåˆ©ç”¨ GPU çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›é«˜æ•ˆå¤„ç†**å¤§è§„æ¨¡çŸ©é˜µä¹˜æ³•**ï¼Œè€Œå°†å¤æ‚åº¦è¾ƒé«˜çš„**çŸ©é˜µæ±‚é€†/çº¿æ€§æ–¹ç¨‹æ±‚è§£**ç•™åœ¨ CPU ä¸Šå®Œæˆã€‚
//--------------------------------------------------------------------------------------------------

//--------------------------------------------------------------------------------------------------
/*
question1:

ä¸ç†è§£ï¼Œè¯·è§£é‡Šï¼Œç”¨ä¾‹å­

    dim3 block(16, 16);
    dim3 grid((n_features + 15) / 16, (n_features + 15) / 16);
    compute_xtx<<<grid, block>>>(X, d_XtX, n_samples, n_features);

è¿™æ®µä»£ç æ˜¯ä¸»æœºç«¯ (CPU) ä»£ç ï¼Œç”¨äºé…ç½®å¹¶å¯åŠ¨è®¡ç®— X^T X çŸ©é˜µçš„ CUDA Kernel (`compute_xtx`)ã€‚

å®ƒçš„æ ¸å¿ƒä½œç”¨æ˜¯ç¡®å®š **çº¿ç¨‹å— (Block) çš„å¤§å°** å’Œ **çº¿ç¨‹ç½‘æ ¼ (Grid) çš„å¤§å°**ï¼Œä»¥ç¡®ä¿æ‰€æœ‰ X^T X çŸ©é˜µçš„å…ƒç´ éƒ½èƒ½è¢«è®¡ç®—åˆ°ã€‚

---

## âš™ï¸ I. çŸ©é˜µå°ºå¯¸ä¸åˆ†å·¥ç›®æ ‡

æˆ‘ä»¬è¦è®¡ç®—çš„ X^T X çŸ©é˜µçš„å°ºå¯¸æ˜¯ n_features * n_featuresã€‚æ¯ä¸ªçº¿ç¨‹è´Ÿè´£è®¡ç®— X^T X ä¸­çš„ä¸€ä¸ªå…ƒç´ ã€‚

| å˜é‡ | å«ä¹‰ | ç¤ºä¾‹å€¼ |
| :--- | :--- | :--- |
| n_features | ç‰¹å¾æ€»æ•°ï¼ˆX^T X çš„ç»´åº¦ï¼‰ | å‡è®¾ n_features = 40 |

---

## ğŸš€ II. Block å°ºå¯¸é…ç½® (block)

dim3\ block(16, 16);

* **å«ä¹‰:** æ¯ä¸ªçº¿ç¨‹å—è¢«é…ç½®ä¸º **16 è¡Œ x 16 åˆ—** çš„äºŒç»´ç»“æ„ã€‚
    * blockDim.x = 16
    * blockDim.y = 16
* **çº¿ç¨‹æ€»æ•°:** 16 * 16 = 256 ä¸ªçº¿ç¨‹ã€‚
* **åˆ†å·¥:** è¿™ 256 ä¸ªçº¿ç¨‹å°†å…±åŒè´Ÿè´£è®¡ç®— X^T X çŸ©é˜µä¸Šçš„ä¸€ä¸ª **16 * 16 çš„å­åŒºåŸŸ**ï¼ˆä¸€ä¸ª Tileï¼‰ã€‚

---

## ğŸ§­ III. Grid å°ºå¯¸è®¡ç®—ä¸é…ç½® (grid)

dim3\ grid((n_features + 15) / 16, (n_features + 15) / 16);

* **ç›®çš„:** ç¡®å®šéœ€è¦å¤šå°‘ä¸ª 16 * 16 çš„çº¿ç¨‹å—æ‰èƒ½è¦†ç›–æ•´ä¸ª n_features * n_features çš„åŒºåŸŸã€‚
* **åŸç†:** ä½¿ç”¨ **å‘ä¸Šå–æ•´é™¤æ³•** (\lceil A / B \rceil = (A + B - 1) / B)ã€‚è¿™é‡Œ A = n_featuresï¼ŒB = 16ã€‚

### ç¤ºä¾‹è§£é‡Š (n_features = 40)

1.  **Grid X ç»´åº¦ (blockIdx.x):**
    Grid_x = (40 + 15) / 16 = 55 / 16 = 3 (æ•´æ•°é™¤æ³•)
    * **ç»“æœ:** Grid.x = 3ã€‚

2.  **Grid Y ç»´åº¦ (blockIdx.y):**
    Grid_y = (40 + 15) / 16 = 3
    * **ç»“æœ:** Grid.y = 3ã€‚

**Grid Size:** 3 * 3 = 9 ä¸ªçº¿ç¨‹å—ã€‚

| Grid | Block æ•°é‡ | è¦†ç›–åŒºåŸŸ |
| :--- | :--- | :--- |
| 3 å— (x æ–¹å‘) | 3 * 16 = 48 åˆ— | X^T X çš„ 40 åˆ—éƒ½è¢«è¦†ç›–ã€‚ |
| 3 å— (y æ–¹å‘) | 3 * 16 = 48 è¡Œ | X^T X çš„ 40 è¡Œéƒ½è¢«è¦†ç›–ã€‚ |

---

## ğŸ¯ IV. Kernel å¯åŠ¨ (`compute_xtx<<<grid, block>>>`)

* **Grid:** 3x3 çº¿ç¨‹å—ç½‘æ ¼ (9 ä¸ª Block)ã€‚
* **Block:** 16x16 çº¿ç¨‹ç»“æ„ (256 ä¸ªçº¿ç¨‹)ã€‚
* **æ€»çº¿ç¨‹æ•°:** 9 * 256 = 2304 ä¸ªçº¿ç¨‹ã€‚

**åˆ†å·¥:** è¿™ 2304 ä¸ªçº¿ç¨‹å°†å…±åŒè®¡ç®— X^T X çŸ©é˜µä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ ã€‚ç”±äº 40 * 40 åªæœ‰ 1600 ä¸ªå…ƒç´ ï¼Œå¤šå‡ºçš„çº¿ç¨‹ä¼šåœ¨ Kernel å†…éƒ¨çš„è¾¹ç•Œæ£€æŸ¥ `if (i >= n_features || j >= n_features)` å¤„é€€å‡ºï¼Œç¡®ä¿ç¨‹åºåªè®¡ç®—æœ‰æ•ˆåŒºåŸŸã€‚

**æ€»ç»“:** è¿™æ®µä»£ç å°† X^T X çŸ©é˜µå‡åŒ€åœ°åˆ’åˆ†æˆ 16 * 16 çš„å°å—ï¼Œå¹¶ä¸ºæ¯ä¸ªå°å—åˆ†é…äº†ä¸€ä¸ªçº¿ç¨‹å—ï¼Œå®ç°äº†çŸ©é˜µä¹˜æ³•çš„å¹¶è¡Œè®¡ç®—ã€‚

//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question2:

ä¸ç†è§£ï¼Œè¯·è§£é‡Šï¼Œç”¨ä¾‹å­

// Compute XtX = X^T * X
__global__ void compute_xtx(const float* __restrict__ X,
                            float* __restrict__ XtX,
                            int n_samples, int n_features) 
    int i = blockIdx.y * blockDim.y + threadIdx.y; // feature i
    int j = blockIdx.x * blockDim.x + threadIdx.x; // feature j
    if (i >= n_features || j >= n_features) return;

    float sum = 0.0f;
    for (int k = 0; k < n_samples; ++k)
        sum += X[k * n_features + i] * X[k * n_features + j];

    XtX[i * n_features + j] = sum;


è¿™æ®µä»£ç æ˜¯è®¡ç®—**æ­£è§„æ–¹ç¨‹** X^T X çŸ©é˜µçš„æ ¸å¿ƒ CUDA Kernelã€‚å®ƒçš„ä»»åŠ¡æ˜¯åˆ©ç”¨ GPU çš„å¹¶è¡Œæ€§ï¼Œé«˜æ•ˆåœ°è®¡ç®— X çŸ©é˜µæ‰€æœ‰**åˆ—ï¼ˆç‰¹å¾ï¼‰ä¹‹é—´**çš„**ç‚¹ç§¯ï¼ˆDot Productï¼‰**ã€‚

-----

## âš™ï¸ I. æ ¸å¿ƒç›®æ ‡ï¼šçŸ©é˜µä¹˜æ³• X^T * X

æˆ‘ä»¬è¦è®¡ç®— C = A * B çš„ç‰¹æ®Šå½¢å¼ï¼Œå³ X^T Xã€‚

  * X æ˜¯ä¸€ä¸ª N_samples * N_features çš„çŸ©é˜µã€‚
  * X^T X æ˜¯ä¸€ä¸ª N_features * N_features çš„çŸ©é˜µã€‚
  * çŸ©é˜µ X^T X ä¸­çš„æ¯ä¸ªå…ƒç´  (i, j)ï¼Œç­‰äº X çŸ©é˜µçš„ç¬¬ i åˆ—å’Œç¬¬ j åˆ—çš„**ç‚¹ç§¯**ã€‚

## ğŸ”¢ II. çº¿ç¨‹åˆ†å·¥ä¸ç´¢å¼•è®¡ç®—

æˆ‘ä»¬å‡è®¾ n_samples=500ï¼ˆæ ·æœ¬æ•°/è¡Œæ•°ï¼‰ï¼Œn_features=100ï¼ˆç‰¹å¾æ•°/åˆ—æ•°ï¼‰ã€‚

### 1\. ç¡®å®šè¾“å‡ºåæ ‡ (Thread Mapping)

```c
int i = blockIdx.y * blockDim.y + threadIdx.y; // feature i (row index)
int j = blockIdx.x * blockDim.x + threadIdx.x; // feature j (col index)
if (i >= n_features || j >= n_features) return;
```

  * **åˆ†å·¥:** æ¯ä¸ªçº¿ç¨‹ (threadIdx.x, threadIdx.y) è´Ÿè´£è®¡ç®— X^T X çŸ©é˜µä¸­çš„ä¸€ä¸ªå”¯ä¸€å…ƒç´  (i, j)ã€‚
  * **ç¤ºä¾‹:** å‡è®¾ä¸€ä¸ªçº¿ç¨‹è®¡ç®— X^T X_10, 20ï¼ˆå³ i=10, j=20ï¼‰ã€‚

### 2\. è¾¹ç•Œæ£€æŸ¥

  * `if (i >= n_features || j >= n_features) return;`ï¼šå¦‚æœçº¿ç¨‹è®¡ç®—å‡ºçš„ç´¢å¼• i æˆ– j è¶…å‡ºäº†ç‰¹å¾æ€»æ•° 100ï¼Œçº¿ç¨‹ç«‹å³é€€å‡ºã€‚è¿™ç¡®ä¿äº†åªè®¡ç®—çŸ©é˜µçš„æœ‰æ•ˆåŒºåŸŸã€‚

-----

## ğŸ”¬ III. æ ¸å¿ƒè®¡ç®—ï¼šç‚¹ç§¯å¾ªç¯ (Dot Product)

```c
float sum = 0.0f;
for (int k = 0; k < n_samples; ++k)
    sum += X[k * n_features + i] * X[k * n_features + j];
```

  * **ç›®çš„:** è®¡ç®— X çŸ©é˜µçš„ç¬¬ i åˆ—å’Œç¬¬ j åˆ—çš„ k ç»´ç‚¹ç§¯ã€‚
  * **å¾ªç¯ (k):** å¾ªç¯éå† N_samples=500 æ¬¡ã€‚
      * æ¯æ¬¡è¿­ä»£ï¼Œk å¯¹åº”äº X çŸ©é˜µçš„**æ ·æœ¬ç´¢å¼•**ï¼ˆè¡Œå·ï¼‰ã€‚
  * **ç´¢å¼•è§£é‡Š:**
      * X[k * n_features + i]ï¼šè¯»å– X çŸ©é˜µçš„ç¬¬ k è¡Œã€ç¬¬ i åˆ—çš„å…ƒç´ ï¼ˆå³ X çš„ç¬¬ i **åˆ—**ä¸Šçš„ç¬¬ k ä¸ªæ ·æœ¬ï¼‰ã€‚
      * X[k * n_features + j]ï¼šè¯»å– X çŸ©é˜µçš„ç¬¬ k è¡Œã€ç¬¬ j åˆ—çš„å…ƒç´ ï¼ˆå³ X çš„ç¬¬ j **åˆ—**ä¸Šçš„ç¬¬ k ä¸ªæ ·æœ¬ï¼‰ã€‚

> **ç¤ºä¾‹:** çº¿ç¨‹è®¡ç®— X^T X_10, 20ã€‚
>
>   * åœ¨ k=0 æ—¶ï¼š sum += X_0, 10 * X_0, 20
>   * åœ¨ k=1 æ—¶ï¼š sum += X_1, 10 * X_1, 20
>   * ...
>   * åœ¨ k=499 æ—¶ï¼š sum += X_499, 10 * X_499, 20
>     è¿™å°±æ˜¯ç¬¬ 10 åˆ—å’Œç¬¬ 20 åˆ—çš„å®Œæ•´ç‚¹ç§¯ã€‚

## ğŸ IV. ç»“æœå­˜å‚¨

```c
XtX[i * n_features + j] = sum;
```

  * å°†è®¡ç®—å‡ºçš„ sum å†™å…¥åˆ° X^T X çŸ©é˜µçš„ (i, j) ä½ç½®ã€‚è¿™é‡Œçš„ç´¢å¼•è®¡ç®—æ˜¯æ ‡å‡†çš„**è¡Œä¸»åº (Row-Major)** å­˜å‚¨ã€‚

**æ€»ç»“:** è¿™ä¸ª Kernel ä»¥é«˜åº¦å¹¶è¡Œçš„æ–¹å¼ï¼Œè®©æ¯ä¸ªçº¿ç¨‹è´Ÿè´£è®¡ç®— X^T X çŸ©é˜µçš„ä¸€ä¸ªå…ƒç´ ï¼Œä»è€Œå¿«é€Ÿå®Œæˆçº¿æ€§å›å½’æ­£è§„æ–¹ç¨‹çš„ç¬¬ä¸€æ­¥ã€‚

//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------

//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------

//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------

//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------

//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------

//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------

//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------

//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------

//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------

//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------------------------------
/*
question0:


//--------------------------------------------------------------------------------------------------


